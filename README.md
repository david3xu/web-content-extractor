# Web Content Extractor

A professional-grade web content extraction tool that extracts and categorizes links from web pages. Built with modern Python practices, clean architecture, and multiple deployment options.

## Features

- **ğŸ” Smart Link Extraction**: Extract all links from web pages with intelligent filtering
- **ğŸ“Š Link Classification**: Automatically categorize links as PDF, YouTube, or other
- **ğŸš€ Multiple Interfaces**: CLI, REST API, and Azure Functions
- **â˜ï¸ Cloud Ready**: Deploy to Azure Functions or run locally with Docker
- **ğŸ“ Multiple Output Formats**: JSON, Text, Markdown, and CSV
- **ğŸ”§ Configurable**: Environment-based configuration with validation
- **ğŸ“ˆ Structured Logging**: Production-ready logging with correlation IDs
- **ğŸ§ª Comprehensive Testing**: Unit and integration tests with high coverage

## Architecture Overview

The application follows clean architecture principles with clear separation of concerns:

```mermaid
graph TB
    subgraph "Presentation Layer"
        CLI[CLI Interface]
        API[FastAPI Server]
        FUNC[Azure Functions]
    end

    subgraph "Application Layer"
        SERVICE[ExtractionService]
    end

    subgraph "Domain Layer"
        MODELS[Domain Models]
        INTERFACES[Protocols]
        EXCEPTIONS[Custom Exceptions]
    end

    subgraph "Infrastructure Layer"
        HTTP[HTTP Client]
        PARSER[HTML Parser]
        CLASSIFIER[Link Classifier]
        STORAGE[Storage]
        FORMATTERS[Formatters]
    end

    CLI --> SERVICE
    API --> SERVICE
    FUNC --> SERVICE
    SERVICE --> MODELS
    SERVICE --> INTERFACES
    SERVICE --> EXCEPTIONS
    SERVICE --> HTTP
    SERVICE --> PARSER
    SERVICE --> CLASSIFIER
    SERVICE --> STORAGE
    SERVICE --> FORMATTERS
```

## Workflow Diagram

```mermaid
sequenceDiagram
    participant User
    participant CLI/API
    participant Service
    participant HTTP
    participant Parser
    participant Classifier
    participant Storage

    User->>CLI/API: Extract URL
    CLI/API->>Service: extract_and_classify(url)
    Service->>HTTP: extract_content(url)
    HTTP-->>Service: HTML content
    Service->>Parser: parse_links(content, url)
    Parser-->>Service: List of links
    Service->>Classifier: classify_links(links)
    Classifier-->>Service: Categorized links
    Service->>Storage: save_result(result)
    Storage-->>Service: Storage location
    Service-->>CLI/API: ExtractionResult
    CLI/API-->>User: Formatted output
```

## Complete Directory Structure

```
web-content-extractor/
â”œâ”€â”€ ğŸ“ src/                          # Source code
â”‚   â”œâ”€â”€ ğŸ“ core/                     # Domain layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ interfaces.py            # Protocol definitions
â”‚   â”‚   â”œâ”€â”€ models.py                # Pydantic domain models
â”‚   â”‚   â”œâ”€â”€ service.py               # Core business logic
â”‚   â”‚   â””â”€â”€ exceptions.py            # Custom exceptions
â”‚   â”œâ”€â”€ ğŸ“ infrastructure/           # Infrastructure layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ http_client.py           # Async HTTP client
â”‚   â”‚   â”œâ”€â”€ html_parser.py           # BeautifulSoup parser
â”‚   â”‚   â”œâ”€â”€ link_classifier.py       # Regex-based classifier
â”‚   â”‚   â”œâ”€â”€ formatters.py            # Output formatters
â”‚   â”‚   â”œâ”€â”€ local_storage.py         # Local file storage
â”‚   â”‚   â””â”€â”€ cloud_storage.py         # Azure Blob storage
â”‚   â”œâ”€â”€ ğŸ“ api/                      # FastAPI web server
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ app.py                   # FastAPI application
â”‚   â”œâ”€â”€ ğŸ“ functions/                # Azure Functions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ extract_http_trigger.py  # HTTP trigger
â”‚   â”‚   â””â”€â”€ extract_blob_trigger.py  # Blob trigger
â”‚   â”œâ”€â”€ cli.py                       # Command-line interface
â”‚   â”œâ”€â”€ settings.py                  # Configuration management
â”‚   â”œâ”€â”€ logging.py                   # Logging setup
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ ğŸ“ tests/                        # Test suite
â”‚   â”œâ”€â”€ ğŸ“ unit/                     # Unit tests
â”‚   â”‚   â”œâ”€â”€ test_core_models.py      # Domain model tests
â”‚   â”‚   â””â”€â”€ test_infrastructure.py   # Infrastructure tests
â”‚   â”œâ”€â”€ ğŸ“ integration/              # Integration tests
â”‚   â”‚   â””â”€â”€ test_extraction_service.py
â”‚   â”œâ”€â”€ conftest.py                  # Pytest configuration
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ ğŸ“ docker/                       # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile                   # Multi-stage build
â”‚   â””â”€â”€ docker-compose.yml           # Local development
â”œâ”€â”€ ğŸ“ azure-functions/              # Azure Functions
â”‚   â”œâ”€â”€ host.json                    # Function app config
â”‚   â”œâ”€â”€ ğŸ“ ExtractHttpTrigger/
â”‚   â”‚   â””â”€â”€ function.json            # HTTP trigger config
â”‚   â””â”€â”€ ğŸ“ ExtractBlobTrigger/
â”‚       â””â”€â”€ function.json            # Blob trigger config
â”œâ”€â”€ ğŸ“ docs/                         # Documentation
â”‚   â”œâ”€â”€ improvement_guide.md
â”‚   â”œâ”€â”€ learning-roadmap.md
â”‚   â””â”€â”€ structure.md
â”œâ”€â”€ ğŸ“ scripts/                      # Utility scripts
â”‚   â”œâ”€â”€ deploy.sh                    # Deployment script
â”‚   â”œâ”€â”€ setup.sh                     # Setup script
â”‚   â””â”€â”€ verify_setup.py              # Project verification
â”œâ”€â”€ ğŸ“ output/                       # Output directory
â”œâ”€â”€ pyproject.toml                   # Poetry configuration
â”œâ”€â”€ Makefile                         # Development commands
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ .gitignore                       # Git ignore rules
â””â”€â”€ .pre-commit-config.yaml          # Pre-commit hooks
```

## Quick Start

### Prerequisites

- Python 3.10+
- Poetry (for dependency management)

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd web-content-extractor

# Install dependencies
make setup

# Verify setup
make verify

# Run a quick test
make run
```

### Basic Usage

```bash
# Extract links from a URL
web-extractor extract https://example.com

# Save results to file
web-extractor extract https://example.com --output results.json --save

# Use different output format
web-extractor extract https://example.com --format markdown

# Batch processing
web-extractor batch https://example1.com https://example2.com --output-dir ./results

# Start API server
web-extractor serve --host 0.0.0.0 --port 8000
```

## Configuration

Configuration is handled through environment variables with the `WEB_EXTRACTOR_` prefix:

```bash
# HTTP Settings
WEB_EXTRACTOR_HTTP_TIMEOUT=30.0
WEB_EXTRACTOR_MAX_RETRIES=3
WEB_EXTRACTOR_USER_AGENT="WebExtractor/1.0"

# Logging
WEB_EXTRACTOR_LOG_LEVEL=INFO
WEB_EXTRACTOR_JSON_LOGS=false

# Storage
WEB_EXTRACTOR_OUTPUT_DIRECTORY=./output

# Azure Storage (optional)
WEB_EXTRACTOR_AZURE_STORAGE_CONNECTION_STRING=your_connection_string
WEB_EXTRACTOR_AZURE_STORAGE_CONTAINER=extraction-results
```

## API Usage

### Start the API Server

```bash
web-extractor serve
```

### API Endpoints

- `GET /health` - Health check
- `POST /extract` - Extract links from URL

### Example API Request

```bash
curl -X POST "http://localhost:8000/extract" \
     -H "Content-Type: application/json" \
     -d '{"url": "https://example.com", "save_result": true}'
```

## Docker Deployment

### Local Development

```bash
# Start with Docker Compose (includes Azurite for local Azure Storage)
cd docker
docker-compose up --build

# Access the API
curl http://localhost:8000/health
```

### Production Build

```bash
# Build the image
docker build -f docker/Dockerfile -t web-extractor .

# Run the container
docker run -p 8000:8000 web-extractor
```

## Azure Functions Deployment

### Prerequisites

- Azure CLI installed
- Azure Functions Core Tools
- Azure subscription

### Deploy to Azure

```bash
# Install Azure Functions dependencies
poetry install --with azure

# Deploy to Azure Functions
cd azure-functions
func azure functionapp publish your-function-app-name
```

### Function Triggers

- **HTTP Trigger**: `POST /api/extract` - Extract links from a single URL
- **Blob Trigger**: Processes JSON files containing URLs for batch extraction

## Development Workflow

```mermaid
graph LR
    A[Clone Repo] --> B[make setup]
    B --> C[make verify]
    C --> D[make test]
    D --> E[make format]
    E --> F[make lint]
    F --> G[Commit Changes]
    G --> H[Push to Repository]
    H --> I[CI/CD Pipeline]
    I --> J[Deploy to Azure]
```

## Development

### Setup Development Environment

```bash
# Install all dependencies including development tools
poetry install --with dev

# Install pre-commit hooks
pre-commit install

# Run tests
make test

# Format code
make format

# Lint code
make lint

# Verify setup
make verify
```

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test categories
pytest tests/unit/
pytest tests/integration/
```

### Code Quality

The project uses several tools to maintain code quality:

- **Black**: Code formatting
- **Ruff**: Fast Python linter
- **MyPy**: Static type checking
- **Pre-commit**: Automated quality checks
- **Pytest**: Testing framework

## Data Flow

```mermaid
flowchart TD
    A[URL Input] --> B[HTTP Client]
    B --> C[HTML Content]
    C --> D[HTML Parser]
    D --> E[Raw Links]
    E --> F[Link Classifier]
    F --> G[Categorized Links]
    G --> H[Result Formatter]
    H --> I[Output Format]
    G --> J[Storage]
    J --> K[Local/Azure Storage]
```

## Link Classification Logic

```mermaid
flowchart TD
    A[Link URL & Text] --> B{Contains PDF pattern?}
    B -->|Yes| C[PDF Link]
    B -->|No| D{Contains YouTube pattern?}
    D -->|Yes| E[YouTube Link]
    D -->|No| F[Other Link]
    C --> G[ExtractedLink Object]
    E --> G
    F --> G
```

## Project Structure

```
web-content-extractor/
â”œâ”€â”€ src/                  # Source code
â”œâ”€â”€ tests/               # Test suite
â”œâ”€â”€ docker/              # Docker configuration
â”œâ”€â”€ azure-functions/     # Azure Functions
â”œâ”€â”€ docs/                # Documentation
â”œâ”€â”€ scripts/             # Deployment scripts
â”œâ”€â”€ output/              # Output directory
â”œâ”€â”€ pyproject.toml       # Poetry configuration
â”œâ”€â”€ Makefile            # Development commands
â””â”€â”€ README.md           # This file
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Ensure all tests pass
6. Submit a pull request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Support

For support and questions:

- Create an issue on GitHub
- Check the documentation in the `docs/` directory
- Review the architecture documentation
